{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ForrestWargo1/alarming_poses/blob/main/InnovationWeek2-mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyaT8yNlXKkP",
        "outputId": "1b79a6ba-157a-4692-f0bf-bbdbe9f9d924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "# class syntax\n",
        "class Color(Enum):\n",
        "    nose = 0\n",
        "    left_eye = 1\n",
        "    right_eye = 2\n",
        "    left_ear = 3\n",
        "    right_ear = 4\n",
        "    left_shoulder = 5\n",
        "    right_shoulder = 6\n",
        "    left_elbow = 7\n",
        "    right_elbow = 8\n",
        "    left_hand = 9\n",
        "    right_hand = 10\n",
        "    left_hip = 11\n",
        "    right_hip = 12\n",
        "    left_knee = 13\n",
        "    right_knee = 14\n",
        "    left_foot = 15\n",
        "    right_foot = 16"
      ],
      "metadata": {
        "id": "PSNp9RkTfrHY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_map = {'nose':0,'left_foot': 16, \"right_foot\": 15,'left_eye':2,\"right_shoulder\":5,'left_shoulder':6,'left_hip':12,'left_hand':9,'left_ear':4}"
      ],
      "metadata": {
        "id": "JV0bQNLTX5Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbiNpdRSXTCs",
        "outputId": "66f3223e-9b15-4370-99b4-41a946636187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'alarming_yolov7_poses' already exists and is not an empty directory.\n",
            "/content/alarming_yolov7_poses\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/1ForrestWargo1/alarming_yolov7_poses.git\n",
        "%cd /content/alarming_yolov7_poses\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git pull https://github.com/1ForrestWargo1/alarming_yolov7_poses.git"
      ],
      "metadata": {
        "id": "lhWXrZTkNH2y",
        "outputId": "5815c332-f806-49e4-9cd9-b0a5776758cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/1ForrestWargo1/alarming_yolov7_poses\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0-kufH5XbLA",
        "outputId": "ddd680f5-94f9-46ea-dc84-7a629e48376b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  153M  100  153M    0     0  96.6M      0  0:00:01  0:00:01 --:--:--  145M\n"
          ]
        }
      ],
      "source": [
        "! curl -L https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt -o yolov7-w6-pose.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EM5_HrK8Xd2V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression_kpt\n",
        "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QNUwIC43Xhn6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_model():\n",
        "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
        "    # Put in inference mode\n",
        "    model.float().eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # half() turns predictions into float16 tensors\n",
        "        # which significantly lowers inference time\n",
        "        model.half().to(device)\n",
        "    return model\n",
        "\n",
        "pose_model = load_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3gIHDqf5Xkja"
      },
      "outputs": [],
      "source": [
        "def run_inference(image,model):\n",
        "    # Resize and pad image\n",
        "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (567, 960, 3)\n",
        "    # Apply transforms\n",
        "    image = transforms.ToTensor()(image) # torch.Size([3, 567, 960])\n",
        "    if torch.cuda.is_available():\n",
        "      image = image.half().to(device)\n",
        "    # Turn image into batch\n",
        "    image = image.unsqueeze(0) # torch.Size([1, 3, 567, 960])\n",
        "    with torch.no_grad():\n",
        "      output, other = model(image)\n",
        "    return output, image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_video(filename, save_file = None,privacy = True, do_draw_avatar = True, do_estimate_activity = True):\n",
        "    cap = cv2.VideoCapture(filename)\n",
        "    # VideoWriter for saving the video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    if not save_file:\n",
        "      save_file =  'test_output.mp4'\n",
        "    out = cv2.VideoWriter(save_file, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "    while cap.isOpened():\n",
        "        (ret, frame) = cap.read()\n",
        "        if ret == True:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if do_estimate_activity or do_draw_avatar:\n",
        "              pose_output,frame = run_inference(frame,pose_model)\n",
        "              pose_output = non_max_suppression_kpt(pose_output, \n",
        "                                     0.25, # Confidence Threshold\n",
        "                                     0.65, # IoU Threshold\n",
        "                                     nc=pose_model.yaml['nc'], # Number of Classes\n",
        "                                     nkpt=pose_model.yaml['nkpt'], # Number of Keypoints\n",
        "                                     kpt_label=True)\n",
        "  \n",
        "              with torch.no_grad():\n",
        "                    pose_output = output_to_keypoint(pose_output)\n",
        "              nimg = frame[0].permute(1, 2, 0) * 255\n",
        "              nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "              frame = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "            else:\n",
        "              pose_output = None\n",
        "\n",
        "            frame = apply_privacy(frame,bboxes = None)\n",
        "            frame = estimate_activity(frame,pose_output)\n",
        "            frame = draw_avatar(frame,pose_output)\n",
        "            #frame = draw_keypoints(pose_output, frame,set_standing_angle = 0,p_img = False)\n",
        "\n",
        "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
        "            out.write(frame)\n",
        "        else:\n",
        "            break\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break"
      ],
      "metadata": {
        "id": "kO2kOcAT900H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_activity(frame,pose_output):\n",
        "  return frame\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7312DsIIB7T5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_privacy(frame,bboxes):\n",
        "  return frame"
      ],
      "metadata": {
        "id": "L9NuzGUvGG3X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_avatar(frame,pose_output):\n",
        "  return frame"
      ],
      "metadata": {
        "id": "RdF9mEXnGVI4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def calc_shoulder_to_foot_dist(points):\n",
        "  foot_points = np.array([points[p_map[\"left_foot\"]*3:p_map[\"left_foot\"]*3+3],points[p_map[\"right_foot\"]*3:p_map[\"right_foot\"]*3+3]])\n",
        "  shoulder_points = np.array([points[p_map[\"left_shoulder\"]*3:p_map[\"left_shoulder\"]*3+3],points[p_map[\"right_shoulder\"]*3:p_map[\"right_shoulder\"]*3+3]])\n",
        "  if sum(foot_points[:,2]) < 0.1 or sum(shoulder_points[:,2]) < 0.1:\n",
        "    return [-1,-1,-1],[-1,-1],[-1,-1]\n",
        "\n",
        "  foot_conf = foot_points[:,2]/sum(foot_points[:,2])\n",
        "  shoulder_conf = shoulder_points[:,2]/sum(shoulder_points[:,2])\n",
        "\n",
        "  avg_foot = foot_points[0,:2]*foot_conf[0] + foot_points[1,:2]*foot_conf[1]\n",
        "  avg_shoulder = shoulder_points[0,:2]*shoulder_conf[0] + shoulder_points[1,:2]*shoulder_conf[1]\n",
        "  return [sum(abs(avg_foot-avg_shoulder)),abs(avg_foot[0]-avg_shoulder[0]),abs(avg_foot[1]-avg_shoulder[1])],avg_foot,avg_shoulder\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "bnG31upAJENU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_distance_chart(nimg,shoulder_to_foot_dist,idx):\n",
        "      thickness = 5\n",
        "      gap = thickness*2\n",
        "\n",
        "      cv2.line(nimg, [0,0+3*idx*gap], [int(shoulder_to_foot_dist[0]),3*idx*gap], (255,0,255), thickness) \n",
        "      cv2.line(nimg, [0,gap+3*idx*gap], [int(shoulder_to_foot_dist[1]),gap+3*idx*gap], (0,0,255), thickness) \n",
        "      cv2.line(nimg, [0,2*gap+3*idx*gap], [int(shoulder_to_foot_dist[2]),2*gap+3*idx*gap], (255,0,0), thickness) \n",
        "      return nimg\n",
        "def draw_posture_lines(nimg,standing_line,current_line):\n",
        "  thickness = 5\n",
        "  cv2.line(nimg, (100,100), np.array((100,100)+standing_line*[100,100]).astype(int),(0,0,0), thickness)\n",
        "  cv2.line(nimg, (200,100), np.array((200,100)+current_line*[100,100]).astype(int),(0,0,0), thickness)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6uP9jsqXvYuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UHbtdzSQeTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standing_angle = []\n",
        "standing_std = None\n",
        "standing_mean = None"
      ],
      "metadata": {
        "id": "1oapyzWhy7Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standing_mean = np.mean(standing_angle,axis = 0)\n",
        "standing_std = np.std(standing_angle,axis = 0)\n",
        "print(standing_mean,standing_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS2QINOK_Hvo",
        "outputId": "ace27f58-49f0-4a47-f2fb-6ee0baf82386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqHeQsjVXqrr"
      },
      "outputs": [],
      "source": [
        "def draw_keypoints(output, image,set_standing_angle,p_img):\n",
        "  global standing_angle\n",
        "  output = non_max_suppression_kpt(output, \n",
        "                                     0.25, # Confidence Threshold\n",
        "                                     0.65, # IoU Threshold\n",
        "                                     nc=pose_model.yaml['nc'], # Number of Classes\n",
        "                                     nkpt=pose_model.yaml['nkpt'], # Number of Keypoints\n",
        "                                     kpt_label=True)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "        output = output_to_keypoint(output)\n",
        "  #print(\"output after\",output.shape,output)\n",
        "  nimg = image[0].permute(1, 2, 0) * 255\n",
        "  nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "  nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "  #print('nimg',nimg.shape)\n",
        "  if p_img and len(output.shape) > 1:\n",
        "    print(\"output shape\",output.shape)\n",
        "    print(output.shape)\n",
        "    bboxs = get_bbox_from_skeleton(output[:, 7:])\n",
        "    p_img.replace_boxes(nimg, bboxs)\n",
        "    nimg = p_img.image\n",
        "  return nimg\n",
        "\n",
        "\n",
        "  for idx in range(output.shape[0]):\n",
        "\n",
        "      plot_skeleton_kpts(nimg, output[idx, 7:].T, 3,write_number = True)\n",
        "      shoulder_to_foot_dist, foot_point, shoulder_point = calc_shoulder_to_foot_dist(output[idx, 7:].T)\n",
        "      if foot_point[0] == -1:\n",
        "        continue\n",
        "      #nimg = add_distance_chart(nimg,shoulder_to_foot_dist,idx)\n",
        "      current_angle = calc_current_angle(foot_point,shoulder_point)\n",
        "      if set_standing_angle:\n",
        "        standing_angle.append(current_angle)\n",
        "      else:\n",
        "        angle_diff = (current_angle - standing_mean)**2\n",
        "        print(\"angle diff\",angle_diff)\n",
        "        draw_posture_lines(nimg,standing_mean,current_angle)\n",
        "        if angle_diff[0] > standing_std[0] or angle_diff[1] > standing_std[1]:\n",
        "          cv2.line(nimg, [300,30], [300,60], (0,255,0), 10) \n",
        "        else:\n",
        "          cv2.line(nimg, [300,30], [300,60], (255,255,255), 10) \n",
        "\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "    \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #calc standing from example video\n",
        "  #compare to laying down cangle\n",
        "  #comapre to sitting angle adding waist -- these weights could be learned (?)\n",
        "\n",
        "\n",
        "      #print(\"test\",shoulder_to_foot_dist)\n",
        "      #print(\"skeleton point\", idx,output[idx, 7:].T, len(output[idx, 7:]) )\n",
        "\n",
        "  return nimg"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQ8AZSJQRIaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_current_angle(foot_point,shoulder_point):\n",
        "  #print(foot_point,shoulder_point)\n",
        "  vec = abs(foot_point-shoulder_point)/sum(abs(foot_point-shoulder_point))\n",
        "  #print(vec)\n",
        "  return vec\n",
        "\n"
      ],
      "metadata": {
        "id": "67obenuCurjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mdxAhJmYsFN"
      },
      "outputs": [],
      "source": [
        "standing_angle = []\n",
        "standing_std = None\n",
        "standing_mean = None\n",
        "pose_estimation_video('/content/drive/MyDrive/Alarm/innovation week/walking.mov','/content/drive/MyDrive/Alarm/innovation week/save/standing_output.mp4')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pose_estimation_video('/content/drive/MyDrive/Alarm/innovation week/privacy_test.mov','/content/drive/MyDrive/Alarm/innovation week/save/privacy_test.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "sjB5uQWiCQQk",
        "outputId": "531d3cde-0c65-42f3-961e-328aaf4e09e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ca79fe978fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpose_estimation_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Alarm/innovation week/privacy_test.mov'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Alarm/innovation week/save/privacy_test.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pose_estimation_video' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class private_image():\n",
        "  def __init__(self):\n",
        "    self.image = []\n",
        "\n",
        "  def replace_boxes(self,new_image,bboxes):\n",
        "    #print(bboxes)\n",
        "    if len(self.image) == 0:\n",
        "      self.image  = new_image*0\n",
        "    for bbox in bboxes:\n",
        "      x1,y1,x2,y2 = bbox\n",
        "      #ensure all values are inside image\n",
        "      x1 = max(0, x1)\n",
        "      y1 = max(0, y1)\n",
        "      x2 = min(self.image.shape[1], x2)\n",
        "      y2 = min(self.image.shape[0], y2)\n",
        "      new_image[y1:y2,x1:x2] =  self.image[y1:y2,x1:x2]\n",
        "      self.image = new_image\n",
        "\n",
        "def get_bbox_from_skeleton(xy_lists):\n",
        "    print(\"xy list\",xy_lists.shape)\n",
        "    bboxes = []\n",
        "    for list in xy_lists:\n",
        "        x_list = []\n",
        "        y_list = []\n",
        "        for i in range(0, len(list), 3):\n",
        "            x_list.append(list[i])\n",
        "            y_list.append(list[i+1])\n",
        "        bboxes.append([int(min(x_list))-100, int(min(y_list))-100, int(max(x_list))+100, int(max(y_list))+100])\n",
        "    return bboxes\n"
      ],
      "metadata": {
        "id": "_NoFZIMfw12X"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_video('/content/drive/MyDrive/Alarm/innovation week/privacy_test.mov','/content/drive/MyDrive/Alarm/innovation week/save/REFACTOR_TEST.mp4')"
      ],
      "metadata": {
        "id": "n1CPfYeaGm6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnpiG_UbZkW0"
      },
      "outputs": [],
      "source": [
        "def pose_estimation_video(filename,save_file = None,privacy = True):\n",
        "    global standing_angle, standing_mean, standing_std\n",
        "    set_standing_angle = len(standing_angle) == 0\n",
        "    if set_standing_angle:\n",
        "      print(\"SETTING STANDING ANGLE\")\n",
        "    else:\n",
        "      print(\"CALCULATING CURRENT ANGLE\")\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(filename)\n",
        "    # VideoWriter for saving the video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    if not save_file:\n",
        "      save_file =  'test_output.mp4'\n",
        "    out = cv2.VideoWriter(save_file, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "    count =0\n",
        "    if privacy:\n",
        "      p_img = private_image() \n",
        "    else:\n",
        "      p_img = None\n",
        "    print('starting')\n",
        "    while cap.isOpened():\n",
        "        \n",
        "        (ret, frame) = cap.read()\n",
        "        count +=1\n",
        "        #print(count)\n",
        "        if ret == True:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            output, frame = run_inference(frame)\n",
        "            \n",
        "  \n",
        "\n",
        "            frame = draw_keypoints(output, frame,set_standing_angle,p_img)\n",
        "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
        "            out.write(frame)\n",
        "            #cv2.imshow('Pose estimation', frame)\n",
        "        else:\n",
        "            break\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    if set_standing_angle:\n",
        "      standing_angle = np.array(standing_angle)\n",
        "      standing_mean = np.mean(standing_angle,axis = 0)\n",
        "      standing_std = np.std(standing_angle,axis = 0)\n",
        "\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnxviHHSndEF1kO0FqU88/",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}